{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f5c90-a1c3-44bd-881f-0df6722cfc10",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Tokenize text\n",
    "* Investigate more model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c688ce0f-a419-4b50-8b75-cf046258a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7590d9af-6fea-4a32-bda4-07c050dfd9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:23:14.540558: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-09 15:23:14.582124: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-09 15:23:14.582162: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-09 15:23:14.582172: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-09 15:23:14.590485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM,\n",
    "    Activation,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Input,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e749152f-0bfc-4d9d-8a60-5663f9dfc2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:23:17.651768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.669576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.669796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(gpus)\n",
    "tf.config.set_logical_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=4000)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2954cc6d-42db-4a5e-a045-d9c96e4b8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"./data/robert_frost.txt\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86d1d4b-a73f-4e42-b0a6-f86dd9dce360",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21ac402-756b-4f84-88eb-57a7ca0334d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d78565-e71c-4266-8a81-f3ad87bcf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 55\n",
    "step = 8\n",
    "\n",
    "sentence = []\n",
    "next_char = []\n",
    "\n",
    "for i in range(0, len(text) - max_length, step):\n",
    "    sentence.append(text[i : i + max_length])\n",
    "    next_char.append(text[i + max_length])\n",
    "\n",
    "sub_data = 1000\n",
    "sentence = sentence[: len(sentence) // sub_data]\n",
    "next_char = next_char[: len(next_char) // sub_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b4864a-7a19-44c0-9a93-298fea405759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 43)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence), len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0263a899-1ec2-483d-a7f8-cd14c7331907",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentence), max_length, len(chars)), dtype=\"int8\")\n",
    "Y = np.zeros((len(sentence), len(chars)), dtype=\"int8\")\n",
    "\n",
    "for i, sent in enumerate(sentence):\n",
    "    for k, char in enumerate(sent):\n",
    "        X[i, k, char_indices[char]] = 1\n",
    "    Y[i, char_indices[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14cdcce-1d04-434f-9c42-49fbb1f309c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 55, 43)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bafed8c-8f3b-4e66-b432-4c270a3186d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:23:17.930593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.930858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.931002: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.985958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.986196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.986346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-09 15:23:17.986467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4000 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:5a:00.0, compute capability: 7.5\n",
      "2024-05-09 15:23:17.999454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:746] failed to allocate 3.91GiB (4194304000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "layers = [\n",
    "    Input(shape=(X.shape[1], X.shape[2])),\n",
    "    # Bidirectional(LSTM(2048, return_sequences=True)),\n",
    "    # Bidirectional(LSTM(2048, return_sequences=True)),\n",
    "    # Bidirectional(LSTM(1024)),\n",
    "    LSTM(1024),\n",
    "    Dense(len(chars), activation=\"softmax\"),\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential(layers)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d88d6fa-e418-469d-a128-720fe94189e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1024)              4374528   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 43)                44075     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4418603 (16.86 MB)\n",
      "Trainable params: 4418603 (16.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff523b5-a91e-432e-9ead-7f4a0cc69ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", min_delta=0.01, patience=5, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bb24b8-a7ff-4855-908f-954978af0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 15:23:20.337334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8800\n",
      "2024-05-09 15:23:20.678038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ac00f095810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-09 15:23:20.678060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "2024-05-09 15:23:20.694453: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-09 15:23:20.844111: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7a80f93de020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7690\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.6451\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.3198\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.5254\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.9581\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2024\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.0667\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.7532\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.4860\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.3073\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3201\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.4591\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4231\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.3008\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.2455\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.2569\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2830\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.2982\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2964\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a80f9d28910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b16c730-ef1d-404b-9fa7-c4f37046463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas), preds\n",
    "\n",
    "\n",
    "def genText(text_to_gen, number_gen=200, temp=1):\n",
    "    generated = text_to_gen\n",
    "    sent = text_to_gen\n",
    "    for i in range(number_gen):\n",
    "        x = np.zeros((1, max_length, len(chars)))\n",
    "        for t, char in enumerate(sent):\n",
    "            x[0, t, char_indices[char]] = 1\n",
    "\n",
    "        pred = model.predict(x, verbose=0)[0]\n",
    "        # next_index = np.argmax(pred,axis=1)\n",
    "        next_index, _ = sample(pred, temp)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sent = sent[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2aaf991-43d1-44a3-b1c7-ffdf7d79b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hntwen;ne int;newv;a  \n",
      "t i;  tihnanh"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text2gen = text[1000:1055]\n",
    "genText(text2gen, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895bc808-b746-47d3-99b3-c2f95a2cd17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d411009-d11d-4e9e-86cb-a576ff790967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
